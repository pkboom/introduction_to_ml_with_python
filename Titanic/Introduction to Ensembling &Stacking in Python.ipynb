{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.18.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re  # regular expressions\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the train and test datasets\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# Store our passenger ID for easy access\n",
    "PassengerId = test[\"PassengerId\"]\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bin edges must be unique: array([0. , 0.5, 2. , 2. , 3. ]).\nYou can drop duplicate edges by setting the 'duplicates' kwarg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m full_data:\n\u001b[1;32m     26\u001b[0m     dataset[\u001b[39m\"\u001b[39m\u001b[39mFare\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39m\u001b[39mFare\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfillna(train[\u001b[39m\"\u001b[39m\u001b[39mFare\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmedian())\n\u001b[0;32m---> 27\u001b[0m train[\u001b[39m\"\u001b[39m\u001b[39mCategoricalFare\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mqcut(train[\u001b[39m\"\u001b[39;49m\u001b[39mFare\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39m4\u001b[39;49m)\n\u001b[1;32m     28\u001b[0m \u001b[39m# Create a New feature CategoricalAge\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m full_data:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/titanic/lib/python3.11/site-packages/pandas/core/reshape/tile.py:379\u001b[0m, in \u001b[0;36mqcut\u001b[0;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[1;32m    376\u001b[0m x_np \u001b[39m=\u001b[39m x_np[\u001b[39m~\u001b[39mnp\u001b[39m.\u001b[39misnan(x_np)]\n\u001b[1;32m    377\u001b[0m bins \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mquantile(x_np, quantiles)\n\u001b[0;32m--> 379\u001b[0m fac, bins \u001b[39m=\u001b[39m _bins_to_cuts(\n\u001b[1;32m    380\u001b[0m     x,\n\u001b[1;32m    381\u001b[0m     bins,\n\u001b[1;32m    382\u001b[0m     labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m    383\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[1;32m    384\u001b[0m     include_lowest\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    385\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    386\u001b[0m     duplicates\u001b[39m=\u001b[39;49mduplicates,\n\u001b[1;32m    387\u001b[0m )\n\u001b[1;32m    389\u001b[0m \u001b[39mreturn\u001b[39;00m _postprocess_for_cut(fac, bins, retbins, dtype, original)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/titanic/lib/python3.11/site-packages/pandas/core/reshape/tile.py:420\u001b[0m, in \u001b[0;36m_bins_to_cuts\u001b[0;34m(x, bins, right, labels, precision, include_lowest, dtype, duplicates, ordered)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(unique_bins) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(bins) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(bins) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    419\u001b[0m     \u001b[39mif\u001b[39;00m duplicates \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 420\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    421\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBin edges must be unique: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(bins)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou can drop duplicate edges by setting the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mduplicates\u001b[39m\u001b[39m'\u001b[39m\u001b[39m kwarg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m         )\n\u001b[1;32m    424\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    425\u001b[0m         bins \u001b[39m=\u001b[39m unique_bins\n",
      "\u001b[0;31mValueError\u001b[0m: Bin edges must be unique: array([0. , 0.5, 2. , 2. , 3. ]).\nYou can drop duplicate edges by setting the 'duplicates' kwarg"
     ]
    }
   ],
   "source": [
    "full_data = [train, test]\n",
    "\n",
    "train[\"Name_length\"] = train[\"Name\"].apply(len)\n",
    "test[\"Name_length\"] = test[\"Name\"].apply(len)\n",
    "\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "train[\"Has_Cabin\"] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test[\"Has_Cabin\"] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in full_data:\n",
    "    dataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\n",
    "\n",
    "# Create new feature IsAlone from FamilySize\n",
    "for dataset in full_data:\n",
    "    dataset[\"IsAlone\"] = 0\n",
    "    dataset.loc[dataset[\"FamilySize\"] == 1, \"IsAlone\"] = 1\n",
    "\n",
    "# Remove all NULLS in the Embarked column\n",
    "# embarked feature has some missing value. and we fill those with the most occurred value ( 'S' ).\n",
    "for dataset in full_data:\n",
    "    dataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "# Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
    "for dataset in full_data:\n",
    "    dataset[\"Fare\"] = dataset[\"Fare\"].fillna(train[\"Fare\"].median())\n",
    "train[\"CategoricalFare\"] = pd.qcut(train[\"Fare\"], 4)\n",
    "\n",
    "# Create a New feature CategoricalAge\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset[\"Age\"].mean()\n",
    "    age_std = dataset[\"Age\"].std()\n",
    "    age_null_count = dataset[\"Age\"].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(\n",
    "        age_avg - age_std, age_avg + age_std, size=age_null_count\n",
    "    )\n",
    "    dataset[\"Age\"][np.isnan(dataset[\"Age\"])] = age_null_random_list\n",
    "    dataset[\"Age\"] = dataset[\"Age\"].astype(int)\n",
    "train[\"CategoricalAge\"] = pd.cut(train[\"Age\"], 5)\n",
    "\n",
    "\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(\" ([A-Za-z]+)\\.\", name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# Create a new feature Title, containing the titles of passenger names\n",
    "for dataset in full_data:\n",
    "    dataset[\"Title\"] = dataset[\"Name\"].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in full_data:\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].replace(\n",
    "        [\n",
    "            \"Lady\",\n",
    "            \"Countess\",\n",
    "            \"Capt\",\n",
    "            \"Col\",\n",
    "            \"Don\",\n",
    "            \"Dr\",\n",
    "            \"Major\",\n",
    "            \"Rev\",\n",
    "            \"Sir\",\n",
    "            \"Jonkheer\",\n",
    "            \"Dona\",\n",
    "        ],\n",
    "        \"Rare\",\n",
    "    )\n",
    "\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].replace(\"Mlle\", \"Miss\")\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].replace(\"Ms\", \"Miss\")\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].replace(\"Mme\", \"Mrs\")\n",
    "\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset[\"Sex\"] = dataset[\"Sex\"].map({\"female\": 0, \"male\": 1}).astype(int)\n",
    "\n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].map(title_mapping)\n",
    "    dataset[\"Title\"] = dataset[\"Title\"].fillna(0)\n",
    "\n",
    "    # Mapping Embarked\n",
    "    dataset[\"Embarked\"] = dataset[\"Embarked\"].map({\"S\": 0, \"C\": 1, \"Q\": 2}).astype(int)\n",
    "\n",
    "    # Mapping Fare\n",
    "    dataset.loc[dataset[\"Fare\"] <= 7.91, \"Fare\"] = 0\n",
    "    dataset.loc[(dataset[\"Fare\"] > 7.91) & (dataset[\"Fare\"] <= 14.454), \"Fare\"] = 1\n",
    "    dataset.loc[(dataset[\"Fare\"] > 14.454) & (dataset[\"Fare\"] <= 31), \"Fare\"] = 2\n",
    "    dataset.loc[dataset[\"Fare\"] > 31, \"Fare\"] = 3\n",
    "    dataset[\"Fare\"] = dataset[\"Fare\"].astype(int)\n",
    "\n",
    "    # Mapping Age\n",
    "    dataset.loc[dataset[\"Age\"] <= 16, \"Age\"] = 0\n",
    "    dataset.loc[(dataset[\"Age\"] > 16) & (dataset[\"Age\"] <= 32), \"Age\"] = 1\n",
    "    dataset.loc[(dataset[\"Age\"] > 32) & (dataset[\"Age\"] <= 48), \"Age\"] = 2\n",
    "    dataset.loc[(dataset[\"Age\"] > 48) & (dataset[\"Age\"] <= 64), \"Age\"] = 3\n",
    "    dataset.loc[dataset[\"Age\"] > 64, \"Age\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
